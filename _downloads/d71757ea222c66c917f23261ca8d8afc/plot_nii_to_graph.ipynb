{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compute connecivity matrices and graph properties from nii files\n\nThe nii_to_graph pipeline performs graph analysis from functional MRI file\nin NIFTI format.\n\nThe **input** data should be a preprocessed, and in the same space (e.g. MNI\nspace) as the template used to define the nodes in the graph.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: David Meunier <david_meunier_79@hotmail.fr>\n\n# License: BSD (3-clause)\nimport os.path as op\n\nimport nipype.pipeline.engine as pe\n\nfrom nipype.interfaces.utility import IdentityInterface\nimport nipype.interfaces.io as nio\n\nimport json  # noqa\nimport pprint  # noqa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if data are available\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nos.system(\"wget --no-check-certificate  --content-disposition https://cloud.int.univ-amu.fr/index.php/s/xft5LeZqgRiPFDi/download\") #noqa\nos.system(\"unzip -o data_nii.zip\")\n\ndata_path = os.path.join(os.getcwd(),\"data_nii\")\n\nassert os.path.exists(data_path), \"Error, data_path is not available\"\n\nROI_mask_file = op.join(data_path,\"ROI_HCP\",\"indexed_mask-ROI_HCP.nii\")\nROI_coords_file = op.join(data_path,\"ROI_HCP\",\"ROI_coords-ROI_HCP.txt\")\nROI_MNI_coords_file =op.join(data_path,\"ROI_HCP\",\"ROI_MNI_coords-ROI_HCP.txt\")\nROI_labels_file = op.join(data_path,\"ROI_HCP\",\"ROI_labels-ROI_HCP.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create our workflow and specify the `base_dir` which tells\nnipype the directory in which to store the outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# workflow directory within the `base_dir`\nconmat_analysis_name = 'conmat'\n\nfrom graphpype.pipelines.nii_to_conmat import create_pipeline_nii_to_conmat # noqa\nfrom graphpype.pipelines.nii_to_conmat import create_pipeline_nii_to_conmat_seg_template # noqa\nfrom graphpype.pipelines.nii_to_conmat import create_pipeline_nii_to_subj_ROI #noqa\n\nmain_workflow = pe.Workflow(name= conmat_analysis_name)\nmain_workflow.base_dir = data_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a node to pass input filenames to DataGrabber from nipype\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_nii = json.load(open(\"params_nii.json\"))\npprint.pprint({'graph parameters': data_nii})\n\nsubject_ids = data_nii[\"subject_ids\"]\nfunc_sessions = data_nii[\"func_sessions\"]\nconf_interval_prob = data_nii[\"conf_interval_prob\"]\n\ninfosource = pe.Node(interface=IdentityInterface(\n    fields=['subject_id','session']),\n    name=\"infosource\")\n\ninfosource.iterables = [('subject_id', subject_ids),\n    ('session', func_sessions)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and a node to grab data. The template_args in this node iterate upon\nthe values in the infosource node\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasource = pe.Node(interface=nio.DataGrabber(\n    infields=['subject_id','session'],\n    outfields= ['img_file','gm_anat_file','wm_anat_file','csf_anat_file']),\n    name = 'datasource')\n\ndatasource.inputs.base_directory = data_path\ndatasource.inputs.template = '%ssub-%s%s%s%s'\ndatasource.inputs.template_args = dict(\nimg_file=[[\"wr\",'subject_id',\"_task-\",'session',\"_bold.nii\"]],\ngm_anat_file=[[\"wc1\",'subject_id',\"\",'',\"_T1w.nii\"]],\nwm_anat_file=[[\"wc2\",'subject_id',\"\",'',\"_T1w.nii\"]],\ncsf_anat_file=[[\"wc3\",'subject_id',\"\",'',\"_T1w.nii\"]],\nrp_file=[[\"rp_\",'subject_id',\"_task-\",'session',\"_bold.txt\"]],\n       )\n\ndatasource.inputs.sort_filelist = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "### reasample images, extract time series and compute correlations\ncor_wf = create_pipeline_nii_to_conmat(main_path=data_path,\n                                       conf_interval_prob=conf_interval_prob,\n                                       resample=True, background_val=0.0)\n\n### link the datasource outputs to the pipeline inputs\nmain_workflow.connect(datasource, 'img_file', cor_wf, 'inputnode.nii_4D_file')\nmain_workflow.connect(datasource, 'gm_anat_file', cor_wf,\n                      'inputnode.gm_anat_file')\nmain_workflow.connect(datasource, 'wm_anat_file', cor_wf,\n                      'inputnode.wm_anat_file')\nmain_workflow.connect(datasource, 'csf_anat_file', cor_wf,\n                      'inputnode.csf_anat_file')\nmain_workflow.connect(datasource, 'rp_file', cor_wf, 'inputnode.rp_file')\n\n### extra arguments: the template used to define nodes\ncor_wf.inputs.inputnode.ROI_mask_file = ROI_mask_file\ncor_wf.inputs.inputnode.ROI_coords_file = ROI_coords_file\ncor_wf.inputs.inputnode.ROI_MNI_coords_file = ROI_MNI_coords_file\ncor_wf.inputs.inputnode.ROI_labels_file = ROI_labels_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then connect the nodes two at a time. We connect the output\nof the infosource node to the datasource node.\nSo, these two nodes taken together can grab data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.connect(infosource, 'subject_id', datasource, 'subject_id')\nmain_workflow.connect(infosource, 'session', datasource, 'session')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# This parameter corrdesponds to the percentage of highest connections retains\n# for the analyses. con_den = 1.0 means a fully connected graphs (all edges\n# are present)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json  # noqa\nimport pprint  # noqa\n\ndata_graph = json.load(open(\"params_graph.json\"))\npprint.pprint({'graph parameters': data_graph})\n\n# density of the threshold\ncon_den = data_graph['con_den']\n\n# The optimisation sequence\nradatools_optim = data_graph['radatools_optim']\n\nfrom graphpype.pipelines.conmat_to_graph import create_pipeline_conmat_to_graph_density ## noqa\n\ngraph_workflow = create_pipeline_conmat_to_graph_density(\n    data_path, con_den=con_den, optim_seq=radatools_optim)\n\nmain_workflow.connect(cor_wf, 'compute_conf_cor_mat.Z_conf_cor_mat_file',\n                      graph_workflow, \"inputnode.conmat_file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# To do so, we first write the workflow graph (optional)\nmain_workflow.write_graph(graph2use='colored')  # colored\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# and visualize it. Take a moment to pause and notice how the connections\n# here correspond to how we connected the nodes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#from scipy.misc import imread  # noqa\n#import matplotlib.pyplot as plt  # noqa\n#img = plt.imread(op.join(data_path, graph_analysis_name, 'graph.png'))\n#plt.figure(figsize=(8, 8))\n#plt.imshow(img)\n#plt.axis('off')\n#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Displaying connectivity Figures\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we are now ready to execute our workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.config['execution'] = {'remove_unnecessary_outputs': 'false'}\n\nmain_workflow.run()\n\n# Run workflow locally on 2 CPUs\n#main_workflow.run(plugin='MultiProc', plugin_args={'n_procs': 2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# plotting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from graphpype.utils_visbrain import visu_graph_modules\nfrom visbrain.objects import SceneObj, BrainObj # noqa\n\nsc = SceneObj(size=(500, 500), bgcolor=(1,1,1))\n\nres_path = op.join(\n    data_path, conmat_analysis_name,\n    \"graph_den_pipe_den_\"+str(con_den).replace(\".\", \"_\"),\n    \"_session_rest_subject_id_01\")\n\nlol_file = op.join(res_path, \"community_rada\", \"Z_List.lol\")\nnet_file = op.join(res_path, \"prep_rada\", \"Z_List.net\")\n\nb_obj = BrainObj(\"B1\", translucent=True)\nsc.add_to_subplot(b_obj, row=0, use_this_cam=True, rotate='left',\n                    title=(\"Modules\"),\n                    title_size=14, title_bold=True, title_color='black')\n\nc_obj,s_obj = visu_graph_modules(lol_file=lol_file, net_file=net_file,\n                            coords_file=ROI_MNI_coords_file,\n                            inter_modules=False)\n\nsc.add_to_subplot(c_obj, row=0)\nsc.add_to_subplot(s_obj, row=0)\n\nsc.preview()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}