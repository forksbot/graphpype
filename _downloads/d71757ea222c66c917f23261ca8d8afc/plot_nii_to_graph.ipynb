{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compute connecivity matrices and graph properties from nii files\n\nThe nii_to_graph pipeline performs graph analysis from functional MRI file\nin NIFTI format.\n\nThe **input** data should be preprocessed (i.e. realigned, coregistered, and segmented), and normalized in the same space (e.g. MNI\nspace) as the template used to define the nodes in the graph.\n\nThe data used in this example are the anat and func from the sub-01 in the  OpenNeuro database ds000208_R1.0.0,  https://openneuro.org/datasets/ds000208/versions/00001, after preprocessing realized with Nipype pipeline create_preprocess_struct_to_mean_funct_4D_spm12, with parameters:\n* TR = 2.5,\n* slice_timing = False,\n* fast_segmenting = True,\n* fwhm = [7.5,7.5,8],\n* nb_scans_to_remove = 0\n\nThe template was generated from the HCP template called HCPMMP1_on_MNI152_ICBM2009a_nlin, by taking a mirror for the right hemisphere and compute a template with 360 ROIS\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: David Meunier <david_meunier_79@hotmail.fr>\n\n# License: BSD (3-clause)\n# sphinx_gallery_thumbnail_number = 2\n\n\nimport os\nimport os.path as op\n\nimport nipype.pipeline.engine as pe\n\nfrom nipype.interfaces.utility import IdentityInterface\nimport nipype.interfaces.io as nio\n\nimport json  # noqa\nimport pprint  # noqa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Origin of the data\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if data are available\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from graphpype.utils_tests import load_test_data\n\ndata_path = load_test_data(\"data_nii\")\n\nROI_mask_file = op.join(data_path,\"ROI_HCP\",\"indexed_mask-ROI_HCP.nii\")\nROI_coords_file = op.join(data_path,\"ROI_HCP\",\"ROI_coords-ROI_HCP.txt\")\nROI_MNI_coords_file =op.join(data_path,\"ROI_HCP\",\"ROI_MNI_coords-ROI_HCP.txt\")\nROI_labels_file = op.join(data_path,\"ROI_HCP\",\"ROI_labels-ROI_HCP.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create our workflow and specify the `base_dir` which tells\nnipype the directory in which to store the outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# workflow directory within the `base_dir`\nconmat_analysis_name = 'conmat'\n\nfrom graphpype.pipelines import create_pipeline_nii_to_conmat # noqa\n\nmain_workflow = pe.Workflow(name= conmat_analysis_name)\nmain_workflow.base_dir = data_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a node to pass input filenames to DataGrabber from nipype\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_nii = json.load(open(\"params_nii.json\"))\npprint.pprint({'graph parameters': data_nii})\n\nsubject_ids = data_nii[\"subject_ids\"]\nfunc_sessions = data_nii[\"func_sessions\"]\nconf_interval_prob = data_nii[\"conf_interval_prob\"]\n\ninfosource = pe.Node(interface=IdentityInterface(\n    fields=['subject_id','session']),\n    name=\"infosource\")\n\ninfosource.iterables = [('subject_id', subject_ids),\n    ('session', func_sessions)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and a node to grab data. The template_args in this node iterate upon\nthe values in the infosource node\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasource = pe.Node(interface=nio.DataGrabber(\n    infields=['subject_id','session'],\n    outfields= ['img_file','gm_anat_file','wm_anat_file','csf_anat_file']),\n    name = 'datasource')\n\ndatasource.inputs.base_directory = data_path\ndatasource.inputs.template = '%ssub-%s%s%s%s'\ndatasource.inputs.template_args = dict(\nimg_file=[[\"wr\",'subject_id',\"_task-\",'session',\"_bold.nii\"]],\ngm_anat_file=[[\"wc1\",'subject_id',\"\",'',\"_T1w.nii\"]],\nwm_anat_file=[[\"wc2\",'subject_id',\"\",'',\"_T1w.nii\"]],\ncsf_anat_file=[[\"wc3\",'subject_id',\"\",'',\"_T1w.nii\"]],\nrp_file=[[\"rp_\",'subject_id',\"_task-\",'session',\"_bold.txt\"]],\n       )\n\ndatasource.inputs.sort_filelist = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "### reasample images, extract time series and compute correlations\ncor_wf = create_pipeline_nii_to_conmat(main_path=data_path,\n                                       conf_interval_prob=conf_interval_prob,\n                                       resample=True, background_val=0.0)\n\n### link the datasource outputs to the pipeline inputs\nmain_workflow.connect(datasource, 'img_file', cor_wf, 'inputnode.nii_4D_file')\nmain_workflow.connect(datasource, 'gm_anat_file', cor_wf,\n                      'inputnode.gm_anat_file')\nmain_workflow.connect(datasource, 'wm_anat_file', cor_wf,\n                      'inputnode.wm_anat_file')\nmain_workflow.connect(datasource, 'csf_anat_file', cor_wf,\n                      'inputnode.csf_anat_file')\nmain_workflow.connect(datasource, 'rp_file', cor_wf, 'inputnode.rp_file')\n\n### extra arguments: the template used to define nodes\ncor_wf.inputs.inputnode.ROI_mask_file = ROI_mask_file\ncor_wf.inputs.inputnode.ROI_coords_file = ROI_coords_file\ncor_wf.inputs.inputnode.ROI_MNI_coords_file = ROI_MNI_coords_file\ncor_wf.inputs.inputnode.ROI_labels_file = ROI_labels_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then connect the nodes two at a time. We connect the output\nof the infosource node to the datasource node.\nSo, these two nodes taken together can grab data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.connect(infosource, 'subject_id', datasource, 'subject_id')\nmain_workflow.connect(infosource, 'session', datasource, 'session')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# This parameter corrdesponds to the percentage of highest connections retains\n# for the analyses. con_den = 1.0 means a fully connected graphs (all edges\n# are present)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# density of the threshold\ncon_den = data_nii['con_den']\n\n# The optimisation sequence\nradatools_optim = data_nii['radatools_optim']\n\nfrom graphpype.pipelines import create_pipeline_conmat_to_graph_density ## noqa\n\ngraph_workflow = create_pipeline_conmat_to_graph_density(\n    data_path, con_den=con_den, optim_seq=radatools_optim)\n\nmain_workflow.connect(cor_wf, 'compute_conf_cor_mat.Z_conf_cor_mat_file',\n                      graph_workflow, \"inputnode.conmat_file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do so, we first write the workflow graph (optional)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.write_graph(graph2use='colored')  # colored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and visualize it. Take a moment to pause and notice how the connections\nhere correspond to how we connected the nodes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.misc import imread  # noqa\nimport matplotlib.pyplot as plt  # noqa\nimg = plt.imread(op.join(data_path, conmat_analysis_name, 'graph.png'))\nplt.figure(figsize=(8, 8))\nplt.imshow(img)\nplt.axis('off')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Displaying connectivity Figures\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we are now ready to execute our workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.config['execution'] = {'remove_unnecessary_outputs': 'false'}\n\nmain_workflow.run()\n\n# Run workflow locally on 2 CPUs\n#main_workflow.run(plugin='MultiProc', plugin_args={'n_procs': 2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# plotting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from graphpype.utils_visbrain import visu_graph_modules\nfrom visbrain.objects import SceneObj, BrainObj # noqa\n\nsc = SceneObj(size=(500, 500), bgcolor=(1,1,1))\n\nres_path = op.join(\n    data_path, conmat_analysis_name,\n    \"graph_den_pipe_den_\"+str(con_den).replace(\".\", \"_\"),\n    \"_session_rest_subject_id_01\")\n\nlol_file = op.join(res_path, \"community_rada\", \"Z_List.lol\")\nnet_file = op.join(res_path, \"prep_rada\", \"Z_List.net\")\n\nb_obj = BrainObj(\"B1\", translucent=True)\nsc.add_to_subplot(b_obj, row=0, use_this_cam=True, rotate='left',\n                    title=(\"Modules\"),\n                    title_size=14, title_bold=True, title_color='black')\n\nc_obj,s_obj = visu_graph_modules(lol_file=lol_file, net_file=net_file,\n                            coords_file=ROI_MNI_coords_file,\n                            inter_modules=False)\n\nsc.add_to_subplot(c_obj, row=0)\nsc.add_to_subplot(s_obj, row=0)\n\nsc.preview()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}