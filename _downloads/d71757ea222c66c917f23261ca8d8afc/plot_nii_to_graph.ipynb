{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compute Conmat from nii files properties from a given connectivity matrix\n\nThe conmat_to_graph pipeline performs graph analysis .\n\nThe **input** data should be a symetrical connecivity matrix in **npy** format.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: David Meunier <david_meunier_79@hotmail.fr>\n\n# License: BSD (3-clause)\nimport os.path as op\n\nimport nipype.pipeline.engine as pe\n\nfrom nipype.interfaces.utility import IdentityInterface\nimport nipype.interfaces.io as nio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if data are available\nneeds to import neuropycon_data\n'pip install neuropycon_data' should do the job...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    import neuropycon_data as nd\nexcept ImportError:\n    print(\"Warning, neuropycon_data not found\")\n    exit()\n\ndata_path = op.join(nd.__path__[0], \"data\", \"data_nii\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create our workflow and specify the `base_dir` which tells\nnipype the directory in which to store the outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# workflow directory within the `base_dir`\nconmat_analysis_name = 'nii_to_graph'\n\nrwm_mask_file = op.join(data_path,\"sub-test_mask-anatWM.nii\")\nrcsf_mask_file = op.join(data_path,\"sub-test_mask-anatCSF.nii\")\n\nROI_mask_file = op.join(data_path,\"Atlas\",\"indexed_mask-Atlas.nii\")\nROI_coords_file = op.join(data_path,\"Atlas\",\"ROI_coords-Atlas.txt\")\nROI_MNI_coords_file =op.join(data_path,\"Atlas\",\"ROI_MNI_coords-Atlas.txt\")\nROI_labels_file = op.join(data_path,\"Atlas\",\"ROI_labels-Atlas.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a node to pass input filenames to DataGrabber from nipype\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subject_ids = ['test']\nfunc_sessions = ['rs']\ninfosource = pe.Node(interface=IdentityInterface(\n    fields=['subject_id','session']),\n    name=\"infosource\")\n\ninfosource.iterables = [('subject_id', subject_ids),\n    ('session', func_sessions)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and a node to grab data. The template_args in this node iterate upon\nthe values in the infosource node\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# template_path = '*%s/conmat_0_coh.npy'\n# template_args = [['freq_band_name']\n# datasource = create_datagrabber(data_path, template_path, template_args)\n\ndatasource = pe.Node(\n    interface=nio.DataGrabber(infields=['subject_id','session'],\n                              outfields=['img_file']),\n    name='datasource')\n\ndatasource = pe.Node(interface=nio.DataGrabber(\n    infields=['subject_id','session'],\n    outfields= ['img_file']),\n    name = 'datasource')\n\ndatasource.inputs.base_directory = data_path\ndatasource.inputs.template = 'sub-%s_task-%s_bold.nii'\ndatasource.inputs.template_args = dict(\n\nimg_file=[['subject_id','session']],\n\n       )\ndatasource.inputs.sort_filelist = True\n\n#0/0\n\nfrom graphpype.pipelines.nii_to_conmat import create_pipeline_nii_to_conmat_seg_template # noqa\n\n\nmain_workflow = pe.Workflow(name= conmat_analysis_name)\nmain_workflow.base_dir = data_path\n\nconf_interval_prob = 0.05\n\n    ###### time series and correlations\ncor_workflow = create_pipeline_nii_to_conmat_seg_template(main_path =\ndata_path, conf_interval_prob = conf_interval_prob)\n\nmain_workflow.connect(datasource,'img_file',\ncor_workflow,'inputnode.nii_4D_file')\n#main_workflow.connect(datasource, 'rp_file', cor_workflow,'inputnode.rp_file')\n\ncor_workflow.inputs.inputnode.wm_anat_file = rwm_mask_file\ncor_workflow.inputs.inputnode.csf_anat_file = rcsf_mask_file\n\ncor_workflow.inputs.inputnode.ROI_mask_file = ROI_mask_file\ncor_workflow.inputs.inputnode.ROI_coords_file = ROI_coords_file\ncor_workflow.inputs.inputnode.ROI_MNI_coords_file = ROI_MNI_coords_file\ncor_workflow.inputs.inputnode.ROI_labels_file = ROI_labels_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then connect the nodes two at a time. We connect the output\nof the infosource node to the datasource node.\nSo, these two nodes taken together can grab data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.connect(infosource, 'subject_id', datasource, 'subject_id')\n\n\nmain_workflow.connect(infosource, 'session', datasource, 'session')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# This parameter corrdesponds to the percentage of highest connections retains\n# for the analyses. con_den = 1.0 means a fully connected graphs (all edges\n# are present)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json  # noqa\nimport pprint  # noqa\n\ndata_graph = json.load(open(\"params_graph.json\"))\npprint.pprint({'graph parameters': data_graph})\n\n# density of the threshold\ncon_den = data_graph['con_den']\n\n# The optimisation sequence\nradatools_optim = data_graph['radatools_optim']\n\nfrom graphpype.pipelines.conmat_to_graph import create_pipeline_conmat_to_graph_density ## noqa\n\ngraph_workflow = create_pipeline_conmat_to_graph_density(\n    data_path, con_den=con_den, optim_seq=radatools_optim)\n\nmain_workflow.connect(cor_workflow, 'compute_conf_cor_mat.Z_conf_cor_mat_file',\n                      graph_workflow, \"inputnode.conmat_file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# To do so, we first write the workflow graph (optional)\nmain_workflow.write_graph(graph2use='colored')  # colored\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# and visualize it. Take a moment to pause and notice how the connections\n# here correspond to how we connected the nodes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#from scipy.misc import imread  # noqa\n#import matplotlib.pyplot as plt  # noqa\n#img = plt.imread(op.join(data_path, graph_analysis_name, 'graph.png'))\n#plt.figure(figsize=(8, 8))\n#plt.imshow(img)\n#plt.axis('off')\n#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we are now ready to execute our workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.config['execution'] = {'remove_unnecessary_outputs': 'false'}\n\n#main_workflow.run()\n\n# Run workflow locally on 2 CPUs\n#main_workflow.run(plugin='MultiProc', plugin_args={'n_procs': 2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# plotting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\n#from visbrain.objects import BrainObj\n\nf_vert = op.join(data_path,'Atlas',\n   'Macaque.F99UA1.LEFT.FLAT.CartSTD.Std-MESH.clean.73730.coord')\nf_face =op.join(data_path,'Atlas',\n    'Macaque.F99UA1.LEFT.FLAT.CartSTD.Std-MESH.clean.73730.topo')\n\nvert = np.genfromtxt(f_vert, skip_header=12, usecols=(1, 2, 3))\nfaces = np.genfromtxt(f_face, skip_header=11).astype(int)\n\n\n#from graphpype.utils_visbrain import visu_graph_modules_roles\n\nfrom graphpype.utils_visbrain import visu_graph_modules # noqa\n\nres_path = op.join(data_path,conmat_analysis_name,\n    \"graph_den_pipe_den_0_1\",'_session_rs_subject_id_test')\n\nlol_file = op.join(res_path,\"community_rada\",\"Z_List.lol\")\n\nprint(lol_file)\n\nnet_file = op.join(res_path,\"prep_rada\",\"Z_List.net\")\n#roles_file = os.path.join(res_path,\"node_roles\",\"node_roles.txt\")\n\nfrom visbrain.objects import SceneObj, BrainObj # noqa\n\nb_obj = BrainObj('monkey', vertices=vert, faces=faces, translucent=False)\n\nsc = SceneObj(size=(1000, 1000), bgcolor=(.1, .1, .1))\n\nsc.add_to_subplot(\n    b_obj, row=0, use_this_cam=True, rotate='left',\n    title=\"Module\",\n    title_size=14, title_bold=True, title_color='white')\n\nc_obj,s_obj = visu_graph_modules(lol_file=lol_file, net_file=net_file,\n                            coords_file=ROI_MNI_coords_file,\n                            labels_file=ROI_labels_file, inter_modules=False,\n                            z_offset=+50)\n\nsc.add_to_subplot(c_obj, row=0)\nsc.add_to_subplot(s_obj, row=0)\n\nsc.preview()\n\nc_colval = {0:\"lightblue\",1:\"red\",2:\"green\",3:\"yellow\",4:\"purple\"}\n\n\nfrom graphpype.utils_visbrain import visu_graph_modules # noqa\n\n#labels_file = op.join(data_path, \"correct_channel_names.txt\")\n#coords_file = op.join(data_path, \"MNI_coords.txt\")\n\n#from visbrain.objects import SceneObj, BrainObj # noqa\n\n#sc = SceneObj(size=(1000, 1000), bgcolor=(.1, .1, .1))\n\n#for nf, freq_band_name in enumerate(freq_band_names):\n\n    #res_path = op.join(\n        #data_path, graph_analysis_name,\n        #\"graph_den_pipe_den_\"+str(con_den).replace(\".\", \"_\"),\n        #\"_freq_band_name_\"+freq_band_name)\n\n    #lol_file = op.join(res_path, \"community_rada\", \"Z_List.lol\")\n    #net_file = op.join(res_path, \"prep_rada\", \"Z_List.net\")\n\n    #b_obj = BrainObj(\"white\", translucent=False)\n    #sc.add_to_subplot(\n        #b_obj, row=nf, use_this_cam=True, rotate='left',\n        #title=(\"Module for {} band\".format(freq_band_name)),\n        #title_size=14, title_bold=True, title_color='white')\n\n    #c_obj,s_obj = visu_graph_modules(lol_file=lol_file, net_file=net_file,\n                               #coords_file=coords_file,\n                               #labels_file=labels_file, inter_modules=False,\n                               #z_offset=+50)\n    #sc.add_to_subplot(c_obj, row=nf)\n    #sc.add_to_subplot(s_obj, row=nf)\n\n\n#sc.preview()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}