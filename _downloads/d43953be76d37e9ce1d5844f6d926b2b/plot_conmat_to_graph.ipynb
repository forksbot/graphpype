{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compute Graph properties from a given connectivity matrix\n\nThe conmat_to_graph pipeline performs graph analysis .\n\nThe **input** data should be a time series matrix in **npy** .\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: David Meunier <david_meunier_79@hotmail.fr>\n\n# License: BSD (3-clause)\n\nimport os.path as op\n\nimport nipype.pipeline.engine as pe\n\nfrom nipype.interfaces.utility import IdentityInterface, Function\nimport nipype.interfaces.io as nio\n\n#import ephypype\n#from ephypype.nodes import create_iterator, create_datagrabber\nfrom ephypype.nodes import get_frequency_band\nfrom ephypype.datasets import fetch_omega_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if data are available\nneeds to import neuropycon_data\n'pip install neuropycon_data' should do the job...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    import neuropycon_data as nd\nexcept ImportError:\n    print(\"Warning, neuropycon_data not found\")\n    exit()\n\ndata_path = op.join(nd.__path__[0], \"data\", \"data_con\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This will be what we will loop on\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "freq_band_names = ['alpha', 'beta']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create our workflow and specify the `base_dir` which tells\nnipype the directory in which to store the outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# workflow directory within the `base_dir`\ngraph_analysis_name = 'graph_analysis'\n\nmain_workflow = pe.Workflow(name=graph_analysis_name)\nmain_workflow.base_dir = data_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a node to pass input filenames to DataGrabber from nipype\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# infosource = create_iterator(['freq_band_name'],\n                             #[freq_band_names])\n\ninfosource = pe.Node(\n        interface=IdentityInterface(fields=['freq_band_name']),\n        name=\"infosource\")\n\ninfosource.iterables = [('freq_band_name',freq_band_names)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and a node to grab data. The template_args in this node iterate upon\nthe values in the infosource node\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# template_path = '*%s/conmat_0_coh.npy'\n# template_args = [['freq_band_name']\n# datasource = create_datagrabber(data_path, template_path, template_args)\n\ndatasource = pe.Node(interface=nio.DataGrabber(infields=['freq_band_name'],\n                                                outfields=['conmat_file']),\n                        name='datasource')\ndatasource.inputs.base_directory = data_path\ndatasource.inputs.template = (\"%s/conmat_0_coh.npy\")\ndatasource.inputs.template_args = dict(\n    conmat_file=[['freq_band_name']])\n\ndatasource.inputs.sort_filelist = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graphpype creates for us a pipeline which can be connected to these\n nodes (datasource and infosource we created. The connectivity pipeline is implemented by the function\n:func:`graphpype.pipelines.conmat_to_graph.create_pipeline_conmat_to_graph_density`,\n thus to instantiate this graph pipeline node, we import it and pass\n our parameters to it.\n In particular, the follwing parameters are of particular importance:\n density of the threshold\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "con_den = 0.1 #\n\n# The optimisation sequence\nradatools_optim = \"WN tfrf 1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "see\nhttp://deim.urv.cat/~sergio.gomez/download.php?f=radatools-5.0-README.txt\nfor more details, but very briefly:\n1) WN for weighted unsigned (typically\ncoherence, pli, etc.) and WS for signed (e.g. Pearson correlation) +\n2) the optimisation sequence, can be used in different order. The sequence\ntfrf is proposed in radatools, and means: t = tabu search , f = fast\nalgorithm, r = reposition algorithm and f = fast algorithm (again)\n3) the last number is the number of repetitions of the algorithm, out of\nwhich the best one is chosen. The higher the number of repetitions, the\nhigher the chance to reach the global maximum, but also the longer the\ncomputation takes. For testing, 1 is admissible, but it is expected to\nhave at least 100 is required for reliable results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The graph pipeline contains several nodes, some are based on radatools\n#\n# In particular, the two nodes are:\n#\n# * :class:`ephypype.interfaces.mne.spectral.SpectralConn` computes spectral connectivity in a given frequency bands\n# * :class:`ephypype.interfaces.mne.spectral.PlotSpectralConn` plot connectivity matrix using the |plot_connectivity_circle| function\n#\n# .. |plot_connectivity_circle| raw:: html\n#\n#   <a href=\"http://martinos.org/mne/stable/generated/mne.viz.plot_connectivity_circle.html#mne.viz.plot_connectivity_circle\" target=\"_blank\">spectral_connectivity function</a>\n\nfrom graphpype.pipelines.conmat_to_graph import create_pipeline_conmat_to_graph_density # noqa\n\ngraph_workflow = create_pipeline_conmat_to_graph_density(\n    data_path, con_den=con_den, optim_seq = radatools_optim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then connect the nodes two at a time. We connect the output\nof the infosource node to the datasource node.\nSo, these two nodes taken together can grab data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.connect(infosource, 'freq_band_name',\n                      datasource, 'freq_band_name')\n\nmain_workflow.connect(datasource, 'conmat_file',\n                      graph_workflow,\"inputnode.conmat_file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do so, we first write the workflow graph (optional)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.write_graph(graph2use='colored')  # colored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and visualize it. Take a moment to pause and notice how the connections\nhere correspond to how we connected the nodes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.misc import imread  # noqa\nimport matplotlib.pyplot as plt  # noqa\nimg = plt.imread(op.join(data_path, graph_analysis_name, 'graph.png'))\nplt.figure(figsize=(8, 8))\nplt.imshow(img)\nplt.axis('off')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we are now ready to execute our workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.config['execution'] = {'remove_unnecessary_outputs': 'false'}\n\n# Run workflow locally on 2 CPUs\n#main_workflow.run(plugin='MultiProc', plugin_args={'n_procs': 2})\n\n# Run workflow\n#main_workflow.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now for viewing it, we will use visbrain, and special functions in utils_visbrain:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from graphpype.utils_visbrain import visu_graph_modules\n\nlabels_file = op.join(data_path, \"correct_channel_names.txt\")\ncoords_file = op.join(data_path, \"correct_channel_coords.txt\")\n\nfor freq_band_name in freq_band_names:\n\n    res_path = op.join(\n        data_path,graph_analysis_name, \"graph_den_pipe_den_0_1\",\n        \"_freq_band_name_\"+freq_band_name)\n\n    lol_file = op.join(res_path,\"community_rada\", \"Z_List.lol\")\n\n    print(lol_file)\n\n    net_file = op.join(res_path,\"prep_rada\", \"Z_List.net\")\n\n    visu = visu_graph_modules(lol_file=lol_file, net_file=net_file,\n                             coords_file=coords_file,\n                             labels_file=labels_file,\n                             modality_type = \"MEG\",inter_modules=False)\n                             #x_offset=0, y_offset=-20, z_offset=-50)\n    #visu.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}