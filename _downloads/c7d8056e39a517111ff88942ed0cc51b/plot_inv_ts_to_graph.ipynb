{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compute Graph properties from a given connectivity matrix\n\nThe inv_ts_to_graph pipeline performs spectral connectivity and graph analysis\nover time series. This workflow makes use of two chained pipelines, and\nrequires both graphpype AND ephypype to be installed.\n\nThe **input** data should be a time series matrix in **npy** format.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: David Meunier <david_meunier_79@hotmail.fr>\n# License: BSD (3-clause)\nimport os.path as op\nimport nipype.pipeline.engine as pe\nimport nipype.interfaces.io as nio\n\nfrom ephypype.nodes import create_iterator\nfrom ephypype.nodes import get_frequency_band"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if data are available\nneeds to import neuropycon_data\n'pip install neuropycon_data' should do the job...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    import neuropycon_data as nd\nexcept ImportError:\n    print(\"Warning, neuropycon_data not found\")\n    exit()\n\ndata_path = op.join(nd.__path__[0], \"data\", \"data_inv_ts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we create our workflow and specify the `base_dir` which tells\nnipype the directory in which to store the outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# workflow directory within the `base_dir`\ngraph_analysis_name = 'inv_ts_to_graph_analysis'\n\nmain_workflow = pe.Workflow(name=graph_analysis_name)\nmain_workflow.base_dir = data_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use a json file for describing the connectivity parameters, loaded\nfrom a json as a dictionnary\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json  # noqa\nimport pprint  # noqa\n\ndata_con = json.load(open(\"params_connectivity.json\"))\npprint.pprint({'connectivity parameters': data_con})\n\nfreq_band_names = data_con['freq_band_names']\nfreq_bands = data_con['freq_bands']\n\n# spectral_connectivity_parameters\ncon_method = data_con['con_method']\nepoch_window_length = data_con['epoch_window_length']\n\n# sampling frequency\nsfreq = data_con['sfreq'] # When starting from raw MEG\n# (.fif) data, can be directly extracted from the file info\n\nfrequency_node = get_frequency_band(freq_band_names, freq_bands)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a node to pass input filenames to DataGrabber from nipype\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subject_ids = ['sub-0003']  # 'sub-0004', 'sub-0006'\ninfosource = create_iterator(['subject_id', 'freq_band_name'],\n                             [subject_ids, freq_band_names])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and a node to grab data. The template_args in this node iterate upon\nthe values in the infosource node\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_path = '*%s_task-rest_run-01_meg_0_60_raw_filt_dsamp_ica_ROI_ts.npy'\n\ndatasource = pe.Node(\n    interface=nio.DataGrabber(infields=['subject_id'], outfields=['ts_file']),\n    name='datasource')\n\ndatasource.inputs.base_directory = data_path\ndatasource.inputs.template = template_path\n\ndatasource.inputs.template_args = dict(ts_file=[['subject_id']])\ndatasource.inputs.sort_filelist = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then use the pipeline used in the previous example `conmat_to_graph pipeline <conmat_to_graph>`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ephypype.pipelines.ts_to_conmat import create_pipeline_time_series_to_spectral_connectivity # noqa\n\nspectral_workflow = create_pipeline_time_series_to_spectral_connectivity(\n    data_path, con_method=con_method,\n    epoch_window_length=epoch_window_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use a json file for describing the graph parameters, loaded\nfrom a json as a dictionnary\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_graph = json.load(open(\"params_graph.json\"))\npprint.pprint({'graph parameters': data_graph})\n\n# density of the threshold. This parameter corrdesponds to the percentage of\n# highest connections retains for the analyses. con_den = 1.0 means a fully\n# connected graphs (all edges are present)\n\ncon_den = data_graph['con_den']\n\n# The optimisation sequence\nradatools_optim = data_graph['radatools_optim']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "see http://deim.urv.cat/~sergio.gomez/download.php?f=radatools-5.0-README.txt\nfor more details, but very briefly:\n\n* 1) WN for weighted unsigned (typically coherence, pli, etc.) and WS for signed (e.g. Pearson correlation)\n\n* 2) the optimisation sequence, can be used in different order. The sequence tfrf is proposed in radatools, and means: t = tabu search , f = fast algorithm, r = reposition algorithm and f = fast algorithm (again)\n\n* 3) the last number is the number of repetitions of the algorithm, out of which the best one is chosen. The higher the number of repetitions, the higher the chance to reach the global maximum, but also the longer the computation takes. For testing, 1 is admissible, but it is expected to have at least 100 is required for reliable results\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graphpype creates for us a graph pipeline,\nimplemented by the function :func: `graphpype.pipelines.conmat_to_graph.create_pipeline_conmat_to_graph_density`\n,thus to instantiate this graph pipeline node, we import it and pass\nour parameters to it.\n\nThe graph pipeline contains several nodes, some are based on radatools\n\nTwo nodes of particular interest are :\n\n* :class:`graphpype.interfaces.radatools.rada.CommRada` computes Community detection based on the previous radatools_optim parameters\n\n* :class:`graphpype.interfaces.radatools.rada.NetPropRada` computes most of the classical graph-based metrics (Small-World, Efficiency, Assortativity, etc.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from graphpype.pipelines.conmat_to_graph import create_pipeline_conmat_to_graph_density ## noqa\n\ngraph_workflow = create_pipeline_conmat_to_graph_density(\n    data_path, con_den=con_den, optim_seq=radatools_optim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then connect the nodes two at a time. We connect the output\nof the infosource node to the datasource node.\nSo, these two nodes taken together can grab data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.connect(infosource, 'subject_id',\n                      datasource, 'subject_id')\n\nmain_workflow.connect(infosource, 'freq_band_name',\n                      frequency_node, 'freq_band_name')\n\nmain_workflow.connect(datasource, 'ts_file',\n                      spectral_workflow, \"inputnode.ts_file\")\n\nspectral_workflow.inputs.inputnode.sfreq = sfreq\n\nmain_workflow.connect(frequency_node, 'freq_bands',\n                      spectral_workflow, 'inputnode.freq_band')\n\nmain_workflow.connect(spectral_workflow, 'spectral.conmat_file',\n                      graph_workflow, \"inputnode.conmat_file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do so, we first write the workflow graph (optional)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.write_graph(graph2use='colored')  # colored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and visualize it. Take a moment to pause and notice how the connections\ncorrespond to how we connected the nodes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#from scipy.misc import imread  # noqa\n#import matplotlib.pyplot as plt  # noqa\n#img = plt.imread(op.join(data_path, graph_analysis_name, 'graph.png'))\n#plt.figure(figsize=(8, 8))\n#plt.imshow(img)\n#plt.axis('off')\n#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we are now ready to execute our workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.config['execution'] = {'remove_unnecessary_outputs': 'false'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run workflow locally on 2 CPUs in parrallel\nmain_workflow.run(plugin='MultiProc', plugin_args={'n_procs': 2})\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plotting modules\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#from graphpype.utils_visbrain import visu_graph_modules # noqa\n\n#labels_file = op.join(data_path, \"label_names.txt\")\n#coords_file = op.join(data_path, \"label_centroid.txt\")\n\n#from visbrain.objects import SceneObj, BrainObj # noqa\n\n#sc = SceneObj(size=(1000, 1000), bgcolor=(1,1,1))\n\n#for nf, freq_band_name in enumerate(freq_band_names):\n    #res_path = op.join(\n        #data_path, graph_analysis_name,\n        #\"graph_den_pipe_den_\"+str(con_den).replace(\".\", \"_\"),\n        #\"_freq_band_name_\"+freq_band_name+\"_subject_id_sub-0003\")\n\n    #lol_file = op.join(res_path, \"community_rada\", \"Z_List.lol\")\n    #net_file = op.join(res_path, \"prep_rada\", \"Z_List.net\")\n\n    #b_obj = BrainObj(\"B1\", translucent=True)\n    #sc.add_to_subplot(b_obj, row=nf, use_this_cam=True, rotate='left',\n                      #title=(\"Module for {} band\".format(freq_band_name)),\n                      #title_size=14, title_bold=True, title_color='black')\n\n    #c_obj,s_obj = visu_graph_modules(lol_file=lol_file, net_file=net_file,\n                               #coords_file=coords_file,\n                               #inter_modules=False)\n\n    #sc.add_to_subplot(c_obj, row=nf)\n    #sc.add_to_subplot(s_obj, row=nf)\n\n#sc.preview()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plotting modules and roles\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from graphpype.utils_visbrain import visu_graph_modules_roles # noqa\n\nlabels_file = op.join(data_path, \"label_names.txt\")\ncoords_file = op.join(data_path, \"label_centroid.txt\")\n\nfrom visbrain.objects import SceneObj, BrainObj # noqa\n\nsc = SceneObj(size=(1000, 1000), bgcolor=(1,1,1))\n\nfor nf, freq_band_name in enumerate(freq_band_names):\n    res_path = op.join(\n        data_path, graph_analysis_name,\n        \"graph_den_pipe_den_\"+str(con_den).replace(\".\", \"_\"),\n        \"_freq_band_name_\"+freq_band_name+\"_subject_id_sub-0003\")\n\n    lol_file = op.join(res_path, \"community_rada\", \"Z_List.lol\")\n    net_file = op.join(res_path, \"prep_rada\", \"Z_List.net\")\n    roles_file = op.join(res_path, \"node_roles\", \"node_roles.txt\")\n\n    b_obj = BrainObj('B1', translucent=True)\n    sc.add_to_subplot(b_obj, row=nf, use_this_cam=True, rotate='left',\n                      title=(\"Module for {} band\".format(freq_band_name)),\n                      title_size=14, title_bold=True, title_color='black')\n\n    c_obj,list_sources = visu_graph_modules_roles(\n        lol_file=lol_file, net_file=net_file, roles_file=roles_file,\n        coords_file=coords_file, inter_modules=True, default_size=10,\n        hub_to_non_hub=3)\n\n    sc.add_to_subplot(c_obj, row=nf)\n\n    for source in list_sources:\n        sc.add_to_subplot(source, row=nf)\n\nsc.preview()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}