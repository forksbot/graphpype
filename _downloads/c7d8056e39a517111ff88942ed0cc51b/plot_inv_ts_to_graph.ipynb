{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compute Graph properties from a given connectivity matrix\n\nThe inv_ts_to_graph pipeline performs spectral connectivity and graph analysis\nover time series. This workflow makes use of two chained pipelines, and\nrequires both graphpype AND ephypype to be installed.\n\nThe **input** data should be a time series matrix in **npy** format.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: David Meunier <david_meunier_79@hotmail.fr>\n# License: BSD (3-clause)\nimport os.path as op\nimport nipype.pipeline.engine as pe\nfrom nipype.interfaces.utility import IdentityInterface, Function\nimport nipype.interfaces.io as nio\n\nfrom ephypype.nodes import create_iterator, create_datagrabber\nfrom ephypype.nodes import get_frequency_band"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if data are available\nneeds to import neuropycon_data\n'pip install neuropycon_data' should do the job...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    import neuropycon_data as nd\nexcept ImportError:\n    print(\"Warning, neuropycon_data not found\")\n    exit()\n\ndata_path = op.join(nd.__path__[0], \"data\", \"data_inv_ts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we create our workflow and specify the `base_dir` which tells\nnipype the directory in which to store the outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# workflow directory within the `base_dir`\ngraph_analysis_name = 'inv_ts_to_graph_analysis'\n\nmain_workflow = pe.Workflow(name=graph_analysis_name)\nmain_workflow.base_dir = data_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then use a special node from ephypype to get the proper frequency band,\ngive its name\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "freq_bands = [[8, 12], [13, 29]]\nfreq_band_names = ['alpha', 'beta']\n\nfrequency_node = get_frequency_band(freq_band_names, freq_bands)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a node to pass input filenames to DataGrabber from nipype\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subject_ids = ['sub-0003']  # 'sub-0004', 'sub-0006'\ninfosource = create_iterator(['subject_id', 'freq_band_name'],\n                             [subject_ids, freq_band_names])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and a node to grab data. The template_args in this node iterate upon\nthe values in the infosource node\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_path = '*%s_task-rest_run-01_meg_0_60_raw_filt_dsamp_ica_ROI_ts.npy'\n\ndatasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'],\n                                               outfields=['ts_file']),\n                        name='datasource')\n\ndatasource.inputs.base_directory = data_path\ndatasource.inputs.template = template_path\n\ndatasource.inputs.template_args = dict(ts_file=[['subject_id']])\ndatasource.inputs.sort_filelist = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then use the pipeline used in the previous example `conmat_to_graph\npipeline <conmat_to_graph>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# spectral_connectivity_parameters\ncon_method = 'coh'\nepoch_window_length = 3.0\n\nsfreq = 2400 # sampling frequency\n# when starting from raw MEG (.fif) data, can be directly extracted from the\n# file info\n\nfrom ephypype.pipelines.ts_to_conmat import create_pipeline_time_series_to_spectral_connectivity # noqa\n\nspectral_workflow = create_pipeline_time_series_to_spectral_connectivity(\n    data_path, con_method=con_method,\n    epoch_window_length=epoch_window_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graphpype creates for us a pipeline which can be connected to these\n nodes (datasource and infosource we created. The connectivity pipeline is implemented by the function\n:func:`graphpype.pipelines.conmat_to_graph.create_pipeline_conmat_to_graph_density`,\n thus to instantiate this graph pipeline node, we import it and pass\n our parameters to it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from graphpype.pipelines.conmat_to_graph import create_pipeline_conmat_to_graph_density # noqa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The graph pipeline contains several nodes, some are based on radatools\n\nTwo nodes of particular interest are :\n\n* :class:`graphpype.interfaces.radatools.rada.CommRada` computes Community detection based on the previous radatools_optim parameters # noqa\n\n* :class:`graphpype.interfaces.radatools.rada.NetPropRada` computes most of the classical graph-based metrics (Small-World, Efficiency, Assortativity, etc.) # noqa\n\nThe follwing parameters are of particular importance:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# density of the threshold\n\ncon_den = 0.1 #\n#con_den = 0.05 #\n#con_den = 0.01 #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This parameter corrdesponds to the percentage of highest connections retains\nfor the analyses. con_den = 1.0 means a fully connected graphs (all edges\nare present)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The optimisation sequence\nradatools_optim = \"WN tfrf 1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "see http://deim.urv.cat/~sergio.gomez/download.php?f=radatools-5.0-README.txt\nfor more details, but very briefly:\n\n* 1) WN for weighted unsigned (typically coherence, pli, etc.) and WS for signed (e.g. Pearson correlation) # noqa\n\n* 2) the optimisation sequence, can be used in different order. The sequence tfrf is proposed in radatools, and means: t = tabu search , f = fast algorithm, r = reposition algorithm and f = fast algorithm (again) # noqa\n\n* 3) the last number is the number of repetitions of the algorithm, out of which the best one is chosen. The higher the number of repetitions, the higher the chance to reach the global maximum, but also the longer the computation takes. For testing, 1 is admissible, but it is expected to have at least 100 is required for reliable results #noqa \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graph_workflow = create_pipeline_conmat_to_graph_density(\n    data_path, con_den=con_den, optim_seq = radatools_optim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then connect the nodes two at a time. We connect the output\nof the infosource node to the datasource node.\nSo, these two nodes taken together can grab data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.connect(infosource, 'subject_id',\n                      datasource, 'subject_id')\n\nmain_workflow.connect(infosource, 'freq_band_name',\n                      frequency_node, 'freq_band_name')\n\nmain_workflow.connect(datasource, 'ts_file',\n                      spectral_workflow,\"inputnode.ts_file\")\n\nspectral_workflow.inputs.inputnode.sfreq = sfreq\n\nmain_workflow.connect(frequency_node, 'freq_bands',\n                      spectral_workflow, 'inputnode.freq_band')\n\nmain_workflow.connect(spectral_workflow, 'spectral.conmat_file',\n                      graph_workflow,\"inputnode.conmat_file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do so, we first write the workflow graph (optional)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.write_graph(graph2use='colored')  # colored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# and visualize it. Take a moment to pause and notice how the connections\n# here correspond to how we connected the nodes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.misc import imread  # noqa\nimport matplotlib.pyplot as plt  # noqa\nimg = plt.imread(op.join(data_path, graph_analysis_name, 'graph.png'))\nplt.figure(figsize=(8, 8))\nplt.imshow(img)\nplt.axis('off')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finally, we are now ready to execute our workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.config['execution'] = {'remove_unnecessary_outputs': 'false'}\n\n# Run workflow locally on 2 CPUs\n#main_workflow.run(plugin='MultiProc', plugin_args={'n_procs': 2})\n# Run workflow\nmain_workflow.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from graphpype.utils_visbrain import visu_graph_modules\n\nlabels_file = op.join(data_path, \"label_names.txt\")\ncoords_file = op.join(data_path, \"label_centroid.txt\")\n\nfrom visbrain.objects import SceneObj, BrainObj\n\nsc = SceneObj(size=(1000, 1000), bgcolor=(.1, .1, .1))\n\nfor nf,freq_band_name in enumerate(freq_band_names):\n\n    res_path = op.join(\n        data_path,graph_analysis_name,\n        \"graph_den_pipe_den_\"+str(con_den).replace(\".\",\"_\"),\n        \"_freq_band_name_\"+freq_band_name + \"_subject_id_sub-0003\")\n\n    lol_file = op.join(res_path,\"community_rada\", \"Z_List.lol\")\n\n    net_file = op.join(res_path,\"prep_rada\", \"Z_List.net\")\n\n    b_obj = BrainObj(\"white\", translucent = True)\n\n    sc.add_to_subplot(b_obj, row = nf,use_this_cam=True, rotate='left',\n        title=(\"Module for {} band\".format(freq_band_name)),\n        title_size=14, title_bold=True, title_color='white')\n\n\n    c_obj = visu_graph_modules(lol_file=lol_file, net_file=net_file,\n                            coords_file=coords_file,\n                             labels_file=labels_file,inter_modules=False)\n                             #x_offset=0, y_offset=-20, z_offset=-50)\n\n    sc.add_to_subplot(c_obj, row=nf)\n\nsc.preview()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}